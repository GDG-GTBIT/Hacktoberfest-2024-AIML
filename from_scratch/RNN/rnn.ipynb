{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for testing each part of the RNN implementation as it is made. <br>\n",
    "There are 2 main parts, the forward pass and the backward pass. <br>\n",
    "The forward pass is straightforward, but the backward pass requires some more work. <br>\n",
    "First is the implementation of the forward pass.\n",
    "\n",
    "The formulas used here have been referenced from https://medium.com/@thisislong/building-a-recurrent-neural-network-from-scratch-ba9b27a42856"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_computation(xt, a_prev, parameters):\n",
    "    # This function is for the computation from one input vector x and the previous hidden state, a_prev, to the next hidden state, a_next and the output, y.\n",
    "    # The input is the input vector x, a_prev, and the parameters Waa, Wax, Wya, ba, and by.\n",
    "    # It returns a_next, y, and the cache for backpropagation.\n",
    "\n",
    "    # Retrieve parameters from \"parameters\"\n",
    "    Waa = parameters[\"Waa\"]\n",
    "    Wax = parameters[\"Wax\"]\n",
    "    Wya = parameters[\"Wya\"]\n",
    "    ba = parameters[\"ba\"]\n",
    "    by = parameters[\"by\"]\n",
    "\n",
    "    # compute next activation state using its formula\n",
    "    a_next = np.tanh(Waa @ a_prev + Wax @ xt + ba)\n",
    "    # compute output of the current cell using its formula\n",
    "    y = Wya @ a_next + by\n",
    "\n",
    "    # store values needed for backpropagation in cache\n",
    "    cache = (a_next, a_prev, xt, parameters)\n",
    "\n",
    "    return a_next, y, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(x, a0, parameters):\n",
    "    # This function uses the previous forward computation to compute the forward pass for a given input sequence.\n",
    "    # The input sequence x is a mini-batch of input vectors.\n",
    "    # The initial hidden state is a0.\n",
    "    # The function returns a list of all the hidden states, a, and the outputs, y, and the list of caches for backpropagation.\n",
    "\n",
    "    # Initialize \"caches\"\n",
    "    caches = []\n",
    "\n",
    "    # Retrieve the necessary dimensions, which are, input shape, batch size, number of time steps, shape of hidden units, and shape of output units\n",
    "    n_x, m, T_x = x.shape\n",
    "    n_y, n_a = parameters[\"Wya\"].shape\n",
    "\n",
    "    # Initialize \"a\", and \"y\" for storing the corresponding values\n",
    "    a = np.zeros((n_a, m, T_x))\n",
    "    y = np.zeros((n_y, m, T_x))\n",
    "\n",
    "    # Initialize \"a_next\" to the initial hidden state\n",
    "    a_next = a0\n",
    "\n",
    "    # loop over all time steps\n",
    "    for t in range(T_x):\n",
    "        # Call forward_computation\n",
    "        a_next, yt, cache = forward_computation(x[:, :, t], a_next, parameters)\n",
    "        # Save the value of the new hidden state in a\n",
    "        a[:, :, t] = a_next\n",
    "        # Save the value of the prediction in y\n",
    "        y[:, :, t] = yt\n",
    "        # Append \"cache\" to \"caches\"\n",
    "        caches.append(cache)\n",
    "\n",
    "    # Add the input which resulted in these parameters\n",
    "    caches = (caches, x)\n",
    "\n",
    "    return a, y, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
